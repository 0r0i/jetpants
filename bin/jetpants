#!/usr/bin/env ruby
jetpants_base_dir = File.expand_path(File.dirname(__FILE__) + '/..')
$:.unshift File.join(jetpants_base_dir, 'lib')
%w[thor pry highline/import colored].each {|g| require g}

module Jetpants

  class CommandSuite < Thor

    def initialize *args
      super
      # setup pry
      Pry.config.prompt = proc {|object, nest_level, _| "# #{object} > "}
    end
    
    # Override Thor.dispatch to allow simple callbacks, which must be before_foo / 
    # after_foo *class* methods of Jetpants::CommandSuite. 
    # These aren't as full-featured as normal Jetpants::Callback: you can only have
    # ONE before_foo or after_foo method (they override instead of stacking); no arg
    # passing; no callback abort exception type. Mostly useful for plugins overriding
    # reminder text before or after a task.
    def self.dispatch(task, given_args, given_ops, config)
      task_name = task || given_args[0]
      self.send "before_#{task_name}" if self.respond_to? "before_#{task_name}"
      super
      self.send "after_#{task_name}" if self.respond_to? "after_#{task_name}"
    end
    
    
    desc 'console', 'Jetpants interactive console'
    def console
      Jetpants.pry
    end
    def self.before_console
      message = [ 'Welcome to the Jetpants Console.  A few notes:',
                  '  - Jetpants interacts with databases via ssh and the root user (BE CAREFUL).',
                  '  - Jetpants relies on having access to a root ssh key in order to perform these operations.',
                  '  - This console operates from inside the Jetpants module namespace by default (Jetpants::DB.new == DB.new, etc).',
                  '  - Jetpants uses a global config file at /etc/jetpants.yaml, or a user override config file at ~/.jetpants.yaml.',
                ].join "\n"
      print "\n#{message}\n\n"
    end
    
    
    desc 'promotion', 'perform a master promotion, changing which node is the master of a pool'
    method_option :demote,  :desc => 'node to demote'
    method_option :promote, :desc => 'node to promote'
    def promotion
      # It's not uncommon for the demoted master to be an offline/unavailable node, so relax Jetpants' normal
      # checks regarding replication threads being in different states.
      Jetpants.verify_replication = false
      
      promoted = options[:promote] ? options[:promote].to_db : nil
      demoted  = options[:demote]  ? options[:demote].to_db  : nil
      
      if promoted && !demoted
        error "Node to promote #{promoted} is not a slave" unless promoted.is_slave?
        demoted = promoted.master
        inform "Will demote #{demoted}, the master of specified promoted node #{promoted}."
      end
      
      if demoted
        demoted.probe
      else
        demoted = ask_node 'Please enter the IP address of the node to demote:'
      end

      if demoted.running?
        error 'Cannot demote a node that has no slaves!' unless demoted.has_slaves?
      else
        inform "Unable to connect to node #{demoted} to demote"
        error  "Unable to perform promotion" unless agree "Please confirm that #{demoted} is offline [yes/no]: "
        
        # An asset-tracker plugin may have been populated the slave list anyway
        if demoted.slaves && demoted.slaves.count > 0
          demoted.slaves.each {|s| s.probe}
        else
          replicas = ask("Please enter a comma-seperated list of IP addresses of all current replicas of #{demoted}: ").split /\s*,\s*/
          error "No replicas entered" unless replicas && replicas.count > 0
          error "User supplied list of replicas appears to be invalid - #{replicas}" unless replicas.all? {|replica| is_ip? replica}
          demoted.instance_eval {@slaves = replicas.map &:to_db}
          demoted.slaves.each do |replica|
            # Validate that they are really slaves of demoted
            error "#{replica} does not appear to be a valid replica of #{demoted}" unless replica.master == demoted
          end
        end
      end
      
      puts
      inform "Summary of affected pool"
      inform "Binary log positions and slave lag shown below are just a snapshot taken at the current time." if demoted.running?
      puts
      demoted.pool(true).summary(true)
      puts
      
      unless promoted
        if demoted.running?
          inform "Recommendation: promote the standby slave with the highest binary log coordinates"
        else
          inform "Recommendation: promote the standby slave or active slave with the highest binary log coordinates"
        end
        promoted = ask_node 'Please enter the IP address of the node to promote: '
      end
      
      error "Unable to determine a node to demote and a node to promote" unless demoted.kind_of?(Jetpants::DB) && promoted.kind_of?(Jetpants::DB)
      error "Node to promote #{promoted} is not a slave of node to demote #{demoted}" unless promoted.master == demoted
      error "Cannot promote a backup slave. Please choose another." if promoted.for_backups?
      
      inform "Going to DEMOTE existing master #{demoted} and PROMOTE new master #{promoted}."
      error "Aborting." unless agree "Proceed? [yes/no]: "
      demoted.pool(true).master_promotion! promoted
    end
    def self.after_promotion
      reminders(
        'Commit/push the configuration in version control.',
        'Deploy the configuration to all machines.',
      )
    end
    
    
    desc 'summary', 'display information about a node in the context of its pool'
    method_option :node, :desc => 'IP address of node to query'
    def summary
      node = ask_node('Please enter node IP: ', options[:node])
      node.pool(true).probe
      describe node
      node.pool(true).summary(true)
    end
    
    
    desc 'pools', 'display a full summary of every pool in the topology'
    def pools
      Jetpants.pools.concurrent_each &:probe
      Jetpants.pools.each &:summary
      
      counts = {master: 0, active_slave: 0, standby_slave: 0, backup_slave: 0}
      Jetpants.pools.map(&:nodes).flatten.each {|n| counts[n.role] += 1}
      
      puts
      puts "%4d global pools" % Jetpants.functional_partitions.count
      puts "%4d shard pools" % Jetpants.shards.count
      puts "---- --------------"
      puts "%4d total pools" % Jetpants.pools.count
      puts
      
      total = 0
      counts.each do |role, count|
        puts "%4d %ss" % [count, role.to_s.tr('_', ' ')]
        total += count
      end
      puts "---- --------------"
      puts "%4d total nodes" % total
      puts
    end

    desc 'pools_compact', 'display a compact summary (master, name, and size) of every pool in the topology'
    def pools_compact
      puts
      Jetpants.shards.each do |s| 
        puts "[%-12s] %8s to %-11s = %3s GB" % [s.ip, s.min_id, s.max_id, s.data_set_size(true)]
      end
      Jetpants.functional_partitions.each do |p| 
        puts "[%-12s] %-23s = %3s GB" % [p.ip, p.name, p.data_set_size(true)]
      end
      puts
    end
    
    
    desc 'regen_config', 'regenerate the application configuration'
    def regen_config
      Jetpants.topology.write_config
    end
    
    
    desc 'clone_slave', 'clone a standby slave'
    method_option :source, :desc => 'IP of node to clone from'
    method_option :target, :desc => 'IP of node to clone to'
    def clone_slave
      puts "This task clones the data set of a standby slave."
      source = ask_node('Please enter IP of node to clone from: ', options[:source])
      describe source
      
      target = options[:target] || ask('Please enter comma-separated list of IP addresses to clone to: ')
      targets = target.split(',').map do |ip|
        ip.strip!
        error "target (#{ip}) does not appear to be an IP." unless is_ip? ip
        ip.to_db
      end
      
      source.start_mysql if ! source.running?
      error "source (#{source}) is not a standby slave" unless source.is_standby?
      
      targets.each do |t|
        error "target #{t} already has a master; please clear out node (including in asset tracker) before proceeding" if t.master
      end
      
      source.enslave_siblings!(targets)
      targets.concurrent_each {|t| t.resume_replication; t.catch_up_to_master}
      source.pool.sync_configuration
      puts "Cloning complete."
      Jetpants.topology.write_config
    end
    def self.after_clone_slave
      reminders(
        'Add the new host(s) to trending and monitoring.'
      )
    end
    
    
    desc 'activate_slave', 'turn a standby slave into an active slave'
    method_option :node, :desc => 'IP of standby slave to activate'
    def activate_slave
      puts "This task turns a standby slave into an active slave, OR alters an active slave's weight."
      node = ask_node('Please enter node IP: ', options[:node])
      describe node

      weight = options[:weight] || ask('Please enter weight, or ENTER for default of 100: ')
      weight = 100 if weight == ''
      weight = weight.to_i
      error "Adding a slave of weight 0 makes no sense, use pull_slave instead" if weight == 0
      
      node.pool.mark_slave_active(node, weight)
      Jetpants.topology.write_config
    end
    
    
    desc 'weigh_slave', 'change the weight of an active slave'
    alias :weigh_slave :activate_slave
    
    
    desc 'pull_slave', 'turn an active slave into a standby slave'
    method_option :node, :desc => 'IP of active slave to pull'
    def pull_slave
      puts "This task turns an active slave into a standby slave."
      node = ask_node('Please enter node IP: ', options[:node])
      describe node
      raise "Node is not an active slave" unless node.role == :active_slave
      node.pool.mark_slave_standby(node)
      Jetpants.topology.write_config
    end
    
    
    desc 'destroy_slave', 'remove a standby slave from its pool'
    method_option :node, :desc => 'IP of standby slave to remove'
    def destroy_slave
      puts "This task removes a standby/backup slave from its pool entirely. THIS IS PERMANENT, ie, it does a RESET SLAVE on the target."
      node = ask_node('Please enter node IP: ', options[:node])
      describe node
      raise "Node is not a standby or backup slave" unless (node.is_standby? || node.for_backups?)
      raise "Aborting" unless ask('Please type YES in all capital letters to confirm removing node from its pool: ') == 'YES'
      node.pool.remove_slave!(node)
    end
    
    
    desc 'rebuild_slave', 'export and re-import data set on a standby slave'
    method_option :node, :desc => 'IP of standby slave to rebuild'
    def rebuild_slave
      puts "This task exports all data on a standby/backup slave and then re-imports it."
      node = ask_node('Please enter node IP: ', options[:node])
      describe node
      raise "Node is not a standby or backup slave" unless (node.is_standby? || node.for_backups?)
      raise "Cannot rebuild non-shard slaves from command suite; use jetpants console instead" unless node.pool.is_a?(Shard)
      node.rebuild!
    end
    
    
    desc 'shard_read_only', 'mark a shard as read-only'
    method_option :min_id, :desc => 'Minimum ID of shard to mark as read-only'
    def shard_read_only
      shard_min = options[:min_id] || ask('Please enter min ID of the shard: ')
      s = Jetpants.topology.shard shard_min
      raise "Shard not found" unless s
      s.state = :read_only
      s.sync_configuration
      Jetpants.topology.write_config
    end
    
    
    desc 'shard_offline', 'mark a shard as offline (not readable or writable)'
    method_option :min_id, :desc => 'Minimum ID of shard to mark as offline'
    def shard_offline
      shard_min = options[:min_id] || ask('Please enter min ID of the shard: ')
      s = Jetpants.topology.shard shard_min
      raise "Shard not found" unless s
      s.state = :offline
      s.sync_configuration
      Jetpants.topology.write_config
    end
    
    
    desc 'shard_online', 'mark a shard as fully online (readable and writable)'
    method_option :min_id, :desc => 'Minimum ID of shard to mark as fully online'
    def shard_online
      shard_min = options[:min_id] || ask('Please enter min ID of the shard: ')
      s = Jetpants.topology.shard shard_min
      raise "Shard not found" unless s
      s.state = :ready
      s.sync_configuration
      Jetpants.topology.write_config
    end
    
    
    desc 'shard_split', 'shard split step 1 of 4: spin up child pools with different portions of data set'
    method_option :min_id, :desc => 'Minimum ID of parent shard to split'
    method_option :max_id, :desc => 'Maximum ID of parent shard to split'
    method_option :ranges, :desc => 'Optional comma-separated list of ranges per child ie "1000-1999,2000-2499" (default if omitted: split evenly)'
    method_option :count,  :desc => 'How many child shards to split the parent into (only necessary if the ranges option is omitted)'
    def shard_split
      shard_min = options[:min_id] || ask('Please enter min ID of the parent shard: ')
      shard_max = options[:max_id] || ask('Please enter max ID of the parent shard: ')
      s = Jetpants.topology.shard shard_min, shard_max
      
      raise "Shard not found" unless s
      raise "Shard isn't in ready state" unless s.state == :ready
      
      ranges = options[:ranges] || ask('Optionally enter comma-separated list of ranges per child ie "1000-1999,2000-2499" [default=even split]: ')
      ranges = false if ranges.strip == ''
      
      if ranges
        supply_ranges = []
        ranges.split(',').each do |my_range|
          my_range.strip!
          my_min, my_max = my_range.split('-', 2)
          my_min = my_min.strip.to_i
          my_max = my_max.strip.to_i
          raise "Supplied range list has gaps!" if supply_ranges.last && supply_ranges.last[1] + 1 != my_min
          supply_ranges << [my_min, my_max]
        end
        children = supply_ranges.count
        raise "Supplied range does not cover parent completely!" if supply_ranges.first[0] != shard_min.to_i || supply_ranges.last[1] != shard_max.to_i
        s.init_children(children, supply_ranges)
        s.split!
      else
        children = options[:count]  || ask('Optionally enter how many children to split into [default=2]: ')
        children = 2 if children == ''
        s.split!(children.to_i)
      end
    end
    def self.before_shard_split
      reminders(
        'This process may take several hours. You probably want to run this from a screen session.',
        'Be especially careful if you are relying on SSH Agent Forwarding for your root key, since this is not screen-friendly.'
      )
    end
    def self.after_shard_split
      reminders(
        'Trending and monitoring setup, as needed.',
        'Proceed to next step: jetpants shard_split_child_reads'
      )
    end
    
    
    # This step is only really necessary if asset-tracker changes don't immediately reflect in application configuration.
    # (ie, if app configuration is a static file that needs to be deployed to webs.)
    desc 'shard_split_child_reads', 'shard split step 2 of 4: move reads to child shards'
    def shard_split_child_reads
      Jetpants.topology.write_config
    end
    def self.after_shard_split_child_reads
      reminders(
        'Commit/push the configuration in version control.',
        'Deploy the configuration to all machines.',
        'Wait for reads to stop on the old parent master.',
        'Proceed to next step: jetpants shard_split_child_writes'
      )
    end
    
    
    desc 'shard_split_child_writes', 'shard split step 3 of 4: move writes to child shards'
    method_option :min_id, :desc => 'Minimum ID of parent shard being split'
    method_option :max_id, :desc => 'Maximum ID of parent shard being split'
    def shard_split_child_writes
      s = ask_shard_being_split
      s.move_writes_to_children
      Jetpants.topology.write_config
    end
    def self.after_shard_split_child_writes
      reminders(
        'Commit/push the configuration in version control.',
        'Deploy the configuration to all machines.',
        'Wait for writes to stop on the old parent master.',
        'Proceed to next step: jetpants shard_split_cleanup',
      )
    end
    
    
    desc 'shard_split_cleanup', 'shard split step 4 of 4: clean up data that replicated to wrong shard'
    method_option :min_id, :desc => 'Minimum ID of parent shard being split'
    method_option :max_id, :desc => 'Maximum ID of parent shard being split'
    def shard_split_cleanup
      s = ask_shard_being_split
      s.cleanup!
    end
    def self.after_shard_split_cleanup
      reminders(
        'Review old nodes for hardware issues before re-using, or simply cancel them.',
      )
    end
    
    
    desc 'shard_cutover', 'truncate the current last shard range, and add a new shard after it'
    method_option :cutover_id, :desc => 'Minimum ID of new last shard being created'
    def shard_cutover
      # ensure the spares are available before beginning
      raise "Not enough total spare machines!" unless Jetpants.topology.count_spares >= Jetpants.standby_slaves_per_pool + 1
      raise "Not enough standby_slave role spare machines!" unless Jetpants.topology.count_spares(role: 'standby_slave') >= Jetpants.standby_slaves_per_pool
      raise "Cannot find a spare master-role machine!" unless Jetpants.topology.count_spares(role: 'master') >= 1

      cutover_id = options[:cutover_id] || ask('Please enter min ID of the new shard to be created: ')
      cutover_id = cutover_id.to_i
      last_shard = Jetpants.topology.shards.select {|s| s.max_id == 'INFINITY' && s.in_config?}.first
      last_shard_master = last_shard.master
      
      # In asset tracker, remove the last shard pool and replace it with a new pool. The new pool
      # has the same master/slaves but now has a non-infinity max ID.
      last_shard.state = :recycle
      last_shard.sync_configuration
      last_shard_replace = Shard.new(last_shard.min_id, cutover_id - 1, last_shard_master)
      last_shard_replace.sync_configuration
      Jetpants.topology.pools << last_shard_replace
      
      # Now put another new shard after that one
      new_last_shard_master = Jetpants.topology.claim_spare(role: 'master')
      new_last_shard_slaves = Jetpants.topology.claim_spares(Jetpants.standby_slaves_per_pool, role: 'standby_slave')
      new_last_shard_slaves.each do |x| 
        x.change_master_to new_last_shard_master
        x.resume_replication
      end
      new_last_shard = Shard.new(cutover_id, 'INFINITY', new_last_shard_master)
      new_last_shard.sync_configuration
      Jetpants.topology.pools << new_last_shard
      
      # Create tables on the new shard's master, obtaining schema from previous last shard
      tables = Table.from_config 'sharded_tables'
      last_shard_master.export_schemata tables
      last_shard_master.host.fast_copy_chain(Jetpants.export_location, new_last_shard_master.host, files: ["create_tables_#{last_shard_master.port}.sql"])
      new_last_shard_master.import_schemata!
      
      # regen config file
      Jetpants.topology.write_config
    end
    def self.after_shard_cutover
      reminders(
        'Trending and monitoring setup, as needed.',
        'Commit/push the configuration in version control.',
        'Deploy the configuration to all machines.',
      )
    end
    
    
    no_tasks do
      def is_ip? address
        address =~ /(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})/
      end

      def error message
        abort ['ERROR:'.red, message].join ' '
      end

      def inform message
        puts message.blue
      end
      
      def describe node
        puts "Node #{node} (#{node.hostname}:#{node.port}) has role #{node.role} in pool #{node.pool(true)}.".green
      end
      
      def ask_node(prompt, supplied_node=false)
        node = supplied_node || ask(prompt)
        error "Node (#{node}) does not appear to be an IP address." unless is_ip? node
        node.to_db
      end
      
      def ask_shard_being_split
        shards_being_split = Jetpants.shards.select {|s| s.children.count > 0}
        if shards_being_split.count == 0
          raise 'No shards are currently being split. You can only use this task after running "jetpants shard_split".'
        elsif shards_being_split.count == 1
          s = shards_being_split[0]
          puts "Detected #{s} as the only shard currently involved in a split operation."
          error "Aborting." unless agree "Is this the right shard that you want to perform this action on? [yes/no]: "
        else
          puts "The following shards are currently involved in a split operation:"
          shards_being_split.each {|sbs| puts "* #{sbs}"}
          puts "Which shard would you like to perform this action on?"
          shard_min = options[:min_id] || ask('Please enter min ID of the parent shard: ')
          shard_max = options[:max_id] || ask('Please enter max ID of the parent shard: ')
          s = Jetpants.topology.shard shard_min, shard_max
          raise "Shard not found" unless s
        end
        raise "Shard isn't in expected state" unless s.state == :deprecated
        s
      end
    end
    
    def self.reminders(*strings)
      strings.map! {|s| "  - #{s}"}
      strings.flatten!
      reminder_text = strings.join "\n"
      noun = (strings.count == 1 ? 'REMINDER' : 'REMINDERS')
      print "\n#{noun}:\n#{reminder_text}\n\n" if strings.count > 0
    end
  end
end

# We load jetpants last so that plugins can monkeypatch Jetpants::CommandSuite if desired.
require 'jetpants'

Jetpants::CommandSuite.start
